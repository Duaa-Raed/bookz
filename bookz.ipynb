{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdpYHIscDNp13VM6TXe4BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Duaa-Raed/bookz/blob/main/bookz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uNE5-zTWyNY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ø£ÙˆÙ„ Ù…Ù„Ù\n",
        "print(\"ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„ (Ù…Ø«Ù„Ø§Ù‹ books.csv):\")\n",
        "uploaded1 = files.upload()\n",
        "df = pd.read_csv(list(uploaded1.keys())[0])\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„:\", list(uploaded1.keys())[0])\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ\n",
        "print(\"ğŸ‘€ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
        "print(df.head())\n",
        "\n",
        "# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø³Ø±ÙŠØ¹Ø© Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
        "print(\"\\nğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:\")\n",
        "print(df.info())\n",
        "\n",
        "# Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø±Ù‚Ù…ÙŠØ©\n",
        "print(\"\\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¹Ø§Ù…Ø©:\")\n",
        "print(df.describe())\n",
        "\n",
        "# ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©\n",
        "print(\"\\nâŒ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "rXo9dj6Fre4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª (EDA)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ø¶Ø¨Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ\n",
        "plt.rcParams['font.family'] = 'Arial'\n",
        "\n",
        "# 1ï¸âƒ£ Ø£ÙƒØ«Ø± Ø§Ù„Ù…Ø¤Ù„ÙÙŠÙ† Ø¥Ù†ØªØ§Ø¬Ù‹Ø§\n",
        "top_authors = df['Author'].value_counts().head(10)\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_authors.values, y=top_authors.index, palette=\"viridis\")\n",
        "plt.title(\"ğŸ“š Ø£ÙƒØ«Ø± Ø§Ù„Ù…Ø¤Ù„ÙÙŠÙ† Ø¥Ù†ØªØ§Ø¬Ù‹Ø§\")\n",
        "plt.xlabel(\"Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØªØ¨\")\n",
        "plt.ylabel(\"Ø§Ù„ÙƒØ§ØªØ¨\")\n",
        "plt.show()\n",
        "\n",
        "# 2ï¸âƒ£ Ø£ÙƒØ«Ø± Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù†ØªØ´Ø§Ø±Ù‹Ø§\n",
        "top_categories = df['Category'].value_counts().head(10)\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_categories.values, y=top_categories.index, palette=\"magma\")\n",
        "plt.title(\"ğŸ·ï¸ Ø£ÙƒØ«Ø± Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù†ØªØ´Ø§Ø±Ù‹Ø§\")\n",
        "plt.xlabel(\"Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØªØ¨\")\n",
        "plt.ylabel(\"Ø§Ù„ØªØµÙ†ÙŠÙ\")\n",
        "plt.show()\n",
        "\n",
        "# 3ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª\n",
        "print(\"ğŸ’° Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø±:\")\n",
        "print(df['Price'].describe())\n",
        "\n",
        "print(\"\\nğŸ“– Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª:\")\n",
        "print(df['Pages'].describe())\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(df['Price'], bins=40, kde=True, color='orange')\n",
        "plt.title(\"ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.histplot(df['Pages'], bins=40, kde=True, color='blue')\n",
        "plt.title(\"ØªÙˆØ²ÙŠØ¹ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 4ï¸âƒ£ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¹Ø± ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.scatterplot(data=df, x=\"Pages\", y=\"Price\", alpha=0.6)\n",
        "plt.title(\"ğŸ“ˆ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¹Ø± ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª\")\n",
        "plt.xlabel(\"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª\")\n",
        "plt.ylabel(\"Ø§Ù„Ø³Ø¹Ø± (Ø¯ÙŠÙ†Ø§Ø±)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-V6jiiZb_t68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ ØµÙØ­Ø§Øª Ø£Ùˆ Ø£Ø³Ø¹Ø§Ø± ØµÙØ±\n",
        "df_clean = df[(df['Pages'] > 0) & (df['Price'] > 0)]\n",
        "\n",
        "print(\"ğŸ“š Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØªØ¨ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:\", len(df_clean))\n",
        "\n",
        "\n",
        "df_clean = df_clean[(df_clean['Price'] < 500) & (df_clean['Pages'] < 2000)]\n",
        "\n",
        "print(\"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©:\", len(df_clean))\n",
        "\n",
        "print(\"ğŸ’° Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:\")\n",
        "print(df_clean['Price'].describe())\n",
        "\n",
        "print(\"\\nğŸ“– Ø§Ù„ØµÙØ­Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:\")\n",
        "print(df_clean['Pages'].describe())"
      ],
      "metadata": {
        "id": "CVO9f2nfCetg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©\n",
        "df.fillna(\"\", inplace=True)\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ù…ÙˆØ­Ù‘Ø¯ Ù„Ù„Ù†ØµÙˆØµ\n",
        "df[\"text\"] = (\n",
        "    \"ğŸ“– Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: \" + df[\"Title\"].astype(str) +\n",
        "    \" âœï¸ Ø§Ù„Ù…Ø¤Ù„Ù: \" + df[\"Author\"].astype(str) +\n",
        "    \" ğŸ·ï¸ Ø§Ù„ØªØµÙ†ÙŠÙ: \" + df[\"Category\"].astype(str) +\n",
        "    \" ğŸ“ Ø§Ù„ÙˆØµÙ: \" + df[\"Description\"].astype(str)\n",
        ")\n",
        "\n",
        "print(\"âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ:\", len(df))\n",
        "print(df[\"text\"].head(3))"
      ],
      "metadata": {
        "id": "dU1qd-PdDeYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ø®ØªØ§Ø±ÙŠ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ)\n",
        "print(\"ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨ (Ù…Ø«Ù„Ø§Ù‹ jamalon dataset.csv):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù\n",
        "df1 = pd.read_csv(list(uploaded.keys())[0])\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„:\", list(uploaded.keys())[0])\n",
        "print(df1.columns)\n",
        "\n",
        "# ğŸ”¹ Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ù…ÙˆØ­Ø¯ Ù„Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ\n",
        "if \"Title\" in df1.columns and \"Description\" in df1.columns:\n",
        "    df1[\"text\"] = df1[\"Title\"].fillna('') + \" - \" + df1[\"Description\"].fillna('')\n",
        "    print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ text Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "else:\n",
        "    print(\"âš ï¸ ØªØ£ÙƒØ¯ÙŠ Ø¥Ù†Ùˆ Ø¹Ù†Ø¯Ùƒ Ø£Ø¹Ù…Ø¯Ø© Title Ùˆ Description ÙÙŠ Ø§Ù„Ù…Ù„Ù.\")\n"
      ],
      "metadata": {
        "id": "-CUbBSD1Gkhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "id": "LkXtbq9Qj29D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ embeddings\n",
        "embeddings = model.encode(df1[\"text\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "# ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ float32 Ù„Ù€ faiss\n",
        "embeddings = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "# Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ù„Ù„Ø¨Ø­Ø«\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ù†Ø¬Ø§Ø­! Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØªØ¨: {len(embeddings)}\")"
      ],
      "metadata": {
        "id": "-i6VOQZLD9NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "print(\"âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨Ø­Ø«:\", index.ntotal)\n"
      ],
      "metadata": {
        "id": "our6_jGnEVxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query, k=3):\n",
        "    query_emb = model.encode([query]).astype(\"float32\")\n",
        "    distances, indices = index.search(query_emb, k)\n",
        "    results = df.iloc[indices[0]]\n",
        "    for i, row in results.iterrows():\n",
        "        print(f\"ğŸ“š {row['Title']} â€” {row['Author']}\")\n",
        "        print(f\"ğŸ“ {row['Description'][:250]}...\")\n",
        "        print(\"â€”\" * 60)\n"
      ],
      "metadata": {
        "id": "VBh8hFRON60h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"ÙƒØªØ¨ Ø¹Ù† Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø¨Ø´Ø±ÙŠØ© ÙˆØ§Ù„Ù†Ø¬Ø§Ø­\")"
      ],
      "metadata": {
        "id": "M5nA_-kgQb6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"Ø£ÙØ¶Ù„ Ø±ÙˆØ§ÙŠØ§Øª Ù†Ø¬ÙŠØ¨ Ù…Ø­ÙÙˆØ¸\")"
      ],
      "metadata": {
        "id": "juUu7Q_KVzD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Ù†Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¯ÙŠÙ„ Ø®ÙÙŠÙ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
        "generator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "def rag_answer(query, k=3):\n",
        "    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø£Ù‚Ø±Ø¨\n",
        "    query_emb = model.encode([query]).astype(\"float32\")\n",
        "    distances, indices = index.search(query_emb, k)\n",
        "    results = df1.iloc[indices[0]]\n",
        "\n",
        "    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ÙƒØªØ¨\n",
        "    context = \"\\n\\n\".join(\n",
        "        [f\"ğŸ“š {r['Title']} â€” {r['Author']}\\n{r['Description']}\" for _, r in results.iterrows()]\n",
        "    )\n",
        "\n",
        "    # Ù†Øµ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
        "    prompt = f\"\"\"\n",
        "    Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {query}\n",
        "\n",
        "    Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ø§Ù„ÙƒØªØ¨:\n",
        "    {context}\n",
        "\n",
        "    âœï¸ Ø£Ø¬Ø¨ Ø¨Ø¥ÙŠØ¬Ø§Ø² ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ø·Ø¨ÙŠØ¹ÙŠ Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø£Ø¹Ù„Ø§Ù‡.\n",
        "    \"\"\"\n",
        "\n",
        "    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n",
        "    answer = generator(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "    print(\"ğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\\n\", answer)\n"
      ],
      "metadata": {
        "id": "b6N0H1VaWM65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_answer(question, retriever, model, tokenizer):\n",
        "    # ğŸ” Ø§Ù„Ø®Ø·ÙˆØ© 1: Ù†Ø¬ÙŠØ¨ Ø§Ù„Ù‚Ø·Ø¹ (Ø§Ù„Ù…ØµØ§Ø¯Ø±) Ø§Ù„Ø£Ù‚Ø±Ø¨ Ù„Ù„Ø³Ø¤Ø§Ù„\n",
        "    docs = retriever.get_relevant_documents(question)\n",
        "    context = \"\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    # âœ¨ Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù†Ø­Ø¶Ø± Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ + Ø§Ù„Ø³ÙŠØ§Ù‚\n",
        "    prompt = f\"Ø³Ø¤Ø§Ù„: {question}\\n\\nØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\\n{context}\\n\\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙØµÙ„Ø©:\"\n",
        "\n",
        "    # ğŸ§  Ø§Ù„Ø®Ø·ÙˆØ© 3: Ù†Ø®Ù„ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¬Ø§ÙˆØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=300)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "oZVY_-JEYj7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "XAUFIKLyZDe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨\n",
        "print(\"ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨ (Ù…Ø«Ù„Ø§Ù‹ jamalon dataset.csv):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„:\", list(uploaded.keys())[0])\n",
        "print(df.columns)\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ù…ÙˆØ­Ù‘Ø¯\n",
        "if \"Title\" in df.columns and \"Description\" in df.columns:\n",
        "    df[\"text\"] = df[\"Title\"].fillna('') + \" - \" + df[\"Description\"].fillna('')\n",
        "    print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ text Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "else:\n",
        "    print(\"âš ï¸ ØªØ£ÙƒØ¯ÙŠ Ø¥Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Title Ùˆ Description Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù.\")\n"
      ],
      "metadata": {
        "id": "yobOlQjUezBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "documents = [Document(page_content=row[\"text\"]) for _, row in df.iterrows()]\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VI7Q6stzYyk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community faiss-cpu sentence-transformers\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ğŸ§© ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨\n",
        "print(\"ğŸ“ Ø­Ù…Ù‘Ù„ÙŠ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨ (Ù…Ø«Ù„Ø§Ù‹ jamalon dataset.csv):\")\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„:\", list(uploaded.keys())[0])\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ù…ÙˆØ­Ø¯ Ù„Ù„Ù†ØµÙˆØµ\n",
        "df.fillna(\"\", inplace=True)\n",
        "df[\"text\"] = (\n",
        "    \"ğŸ“– Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: \" + df[\"Title\"].astype(str) +\n",
        "    \" âœï¸ Ø§Ù„Ù…Ø¤Ù„Ù: \" + df[\"Author\"].astype(str) +\n",
        "    \" ğŸ·ï¸ Ø§Ù„ØªØµÙ†ÙŠÙ: \" + df[\"Category\"].astype(str) +\n",
        "    \" ğŸ“ Ø§Ù„ÙˆØµÙ: \" + df[\"Description\"].astype(str)\n",
        ")\n",
        "\n",
        "# ğŸ§  Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø´Ø¹Ø§Ø¹ÙŠØ©\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "documents = [Document(page_content=row[\"text\"]) for _, row in df.iterrows()]\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ retriever (Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø«)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ù†Ø¬Ø§Ø­!\")\n"
      ],
      "metadata": {
        "id": "Durh3qGzmhfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3ShFgnuGjE0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_books_bot(query):\n",
        "    # ğŸ” Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    results = retriever.invoke(query)\n",
        "\n",
        "    # ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„ØªØ´Ù…Ù„ ÙÙ‚Ø· Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨\n",
        "    filtered = [doc for doc in results if any(word in doc.page_content for word in query.split())]\n",
        "\n",
        "    if not filtered:\n",
        "        print(\"ğŸ¤– Ù†Ø¹ØªØ°Ø±ØŒ Ù„Ø§ ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨.\")\n",
        "        return\n",
        "\n",
        "    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in filtered])\n",
        "\n",
        "    # ğŸ§  Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ prompt\n",
        "    prompt = f\"\"\"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ø®ØªØµ Ø¨Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ø±ÙˆØ§ÙŠØ§Øª.\n",
        "Ø§Ø¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¯Ù†Ø§Ù‡ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªØµØ± ÙˆÙˆØ§Ø¶Ø­ Ø¯ÙˆÙ† Ø¥Ø¹Ø§Ø¯Ø© Ø¹Ø±Ø¶Ù‡Ø§.\n",
        "\n",
        "Ø§Ù„Ù…Ø¹Ø±ÙØ©:\n",
        "{context}\n",
        "\n",
        "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {query}\n",
        "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\"\"\"\n",
        "\n",
        "    # ğŸ—£ï¸ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=180)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬\n",
        "    if \"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\" in answer:\n",
        "        answer = answer.split(\"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\")[-1].strip()\n",
        "\n",
        "    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©\n",
        "    if not answer or len(answer) < 15:\n",
        "        print(\"ğŸ¤– Ù†Ø¹ØªØ°Ø±ØŒ Ù„Ø§ ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨.\")\n",
        "    else:\n",
        "        print(\"ğŸ¤–\", answer)\n"
      ],
      "metadata": {
        "id": "Md9Y167Yjne_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸ“š Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØµØ­Ø­ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… gemini-pro Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«)\n",
        "# ==========================================\n",
        "!pip install -q sentence-transformers faiss-cpu pandas google-generativeai\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "# 1ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Gemini API\n",
        "print(\"ğŸ”‘ Ø§Ø­ØµÙ„ÙŠ Ø¹Ù„Ù‰ API Key Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù†: https://makersuite.google.com/app/apikey\")\n",
        "api_key = input(\"Ø£Ø¯Ø®Ù„ÙŠ API Key: \").strip()\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# ğŸš¨ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªÙ‚Ø± gemini-pro\n",
        "gemini_model = genai.GenerativeModel('gemini-pro')\n",
        "print(\"âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ Gemini!\")\n",
        "\n",
        "# 2ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£Ø®ÙŠØ± Ø§Ù„Ø°ÙŠ ØªÙ… Ø­ÙØ¸Ù‡)\n",
        "print(\"\\nğŸ“ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨:\")\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "\n",
        "df.fillna(\"\", inplace=True)\n",
        "df[\"text\"] = (\n",
        "    df[\"Title\"].astype(str) + \" | \" +\n",
        "    df[\"Author\"].astype(str) + \" | \" +\n",
        "    df[\"Description\"].astype(str)\n",
        ")\n",
        "\n",
        "# 3ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Embeddings\n",
        "print(\"ğŸ” Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨Ø­Ø«...\")\n",
        "\n",
        "# ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© GPU\n",
        "if 'embeddings' in locals() or 'embeddings' in globals():\n",
        "    del embeddings\n",
        "if 'model' in locals() or 'model' in globals():\n",
        "    del model\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© GPU.\")\n",
        "\n",
        "# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµØ­ÙŠØ­ all-MiniLM-L6-v2\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø¯ÙØ¹Ø© ØµØºÙŠØ±\n",
        "BATCH_SIZE = 16\n",
        "embeddings = model.encode(df[\"text\"].tolist(), show_progress_bar=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "embeddings_array = np.array(embeddings).astype('float32')\n",
        "index = faiss.IndexFlatL2(embeddings_array.shape[1])\n",
        "index.add(embeddings_array)\n",
        "print(f\"âœ… Ø¬Ø§Ù‡Ø²! ({len(df)} ÙƒØªØ§Ø¨)\")\n",
        "\n",
        "# 4ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« + Gemini\n",
        "def ask_gemini(query, k=3):\n",
        "    \"\"\"Ø¨Ø­Ø« Ø°ÙƒÙŠ Ù…Ø¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ù† Gemini\"\"\"\n",
        "\n",
        "    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    query_emb = model.encode([query]).astype('float32')\n",
        "    distances, indices = index.search(query_emb, k)\n",
        "\n",
        "    # ØªØ¬Ù…ÙŠØ¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØªØ¨\n",
        "    books_info = []\n",
        "    for idx in indices[0]:\n",
        "        book = df.iloc[idx]\n",
        "        books_info.append(f\"\"\"\n",
        "ğŸ“– {book['Title']}\n",
        "âœï¸ Ø§Ù„Ù…Ø¤Ù„Ù: {book['Author']}\n",
        "ğŸ“ Ø§Ù„ÙˆØµÙ: {book['Description'][:300]}\n",
        "\"\"\")\n",
        "\n",
        "    context = \"\\n\\n\".join(books_info)\n",
        "\n",
        "    # Ø¥Ø¹Ø¯Ø§Ø¯ Prompt Ù„Ù€ Gemini\n",
        "    prompt = f\"\"\"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØªØ¨Ø© Ø°ÙƒÙŠ. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n",
        "\n",
        "{context}\n",
        "\n",
        "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {query}\n",
        "\n",
        "Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙÙŠØ¯Ø© ÙˆÙ…Ø®ØªØµØ±Ø© (3-4 Ø¬Ù…Ù„ ÙÙ‚Ø·)ØŒ ÙˆØ§Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Gemini\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "\n",
        "        print(f\"\\nğŸ” Ø³Ø¤Ø§Ù„Ùƒ: {query}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\nğŸ¤– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\")\n",
        "        print(response.text)\n",
        "        print(\"\\nğŸ“š Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            book = df.iloc[idx]\n",
        "            print(f\"\\n{i+1}. {book['Title']} - {book['Author']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ Gemini: {e}\")\n",
        "        print(\"ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø©:\")\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            book = df.iloc[idx]\n",
        "            print(f\"\\n{i+1}. ğŸ“– {book['Title']}\")\n",
        "            print(f\" Â  âœï¸ {book['Author']}\")\n",
        "            print(f\" Â  ğŸ“ {book['Description'][:200]}...\")\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ§ª ØªØ¬Ø±Ø¨Ø©\n",
        "# ==========================================\n",
        "print(\"\\n\\nâœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø²!\")\n",
        "\n",
        "# ... (Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙƒØªØ¨)"
      ],
      "metadata": {
        "id": "17ZrW4aHABYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸ§ª ØªØ¬Ø±Ø¨Ø©\n",
        "# ==========================================\n",
        "print(\"\\n\\nâœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø²!\")\n",
        "\n",
        "ask_gemini(\"Ø£Ø±ÙŠØ¯ ÙƒØªØ¨ Ø¹Ù† Ø§Ù„ÙÙ„Ø³ÙØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©\")\n",
        "ask_gemini(\"Ù…Ø§ Ù‡ÙŠ Ø£ÙØ¶Ù„ Ø±ÙˆØ§ÙŠØ© Ø¹Ø±Ø¨ÙŠØ© Ø­Ø¯ÙŠØ«Ø©ØŸ\")\n",
        "ask_gemini(\"ÙƒØªØ¨ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø£Ø·ÙØ§Ù„ Ø¹Ù…Ø± 10 Ø³Ù†ÙˆØ§Øª\")\n",
        "\n",
        "# ÙˆØ¶Ø¹ ØªÙØ§Ø¹Ù„ÙŠ\n",
        "print(\"\\n\\nğŸ’¬ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø³Ø¤Ø§Ù„ (Ø£Ùˆ 'Ø®Ø±ÙˆØ¬' Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡):\")\n",
        "while True:\n",
        "    q = input(\"\\nâ“ Ø³Ø¤Ø§Ù„Ùƒ: \").strip()\n",
        "    if q.lower() in ['Ø®Ø±ÙˆØ¬', 'exit']:\n",
        "        break\n",
        "    if q:\n",
        "        ask_gemini(q)"
      ],
      "metadata": {
        "id": "CDMtsFDytmZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸ“š Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø¸ÙŠÙ ÙˆØ§Ù„Ù…Ø¨Ø³Ø·)\n",
        "# ==========================================\n",
        "!pip install -q sentence-transformers faiss-cpu pandas google-generativeai\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "# 1ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Gemini API\n",
        "print(\"ğŸ”‘ Ø§Ø­ØµÙ„ÙŠ Ø¹Ù„Ù‰ API Key Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù†: https://makersuite.google.com/app/apikey\")\n",
        "api_key = input(\"Ø£Ø¯Ø®Ù„ÙŠ API Key: \").strip()\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# ğŸš¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø« ÙˆØ§Ù„Ø£ÙƒØ«Ø± ØªÙˆØ§ÙÙ‚Ø§Ù‹\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "print(\"âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ Gemini!\")\n",
        "\n",
        "# 2ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "print(\"\\nğŸ“ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù Ø§Ù„ÙƒØªØ¨:\")\n",
        "# ØªØ£ÙƒØ¯ÙŠ Ù…Ù† Ø¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ´ØºÙŠÙ„\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "\n",
        "df.fillna(\"\", inplace=True)\n",
        "df[\"text\"] = (\n",
        "    df[\"Title\"].astype(str) + \" | \" +\n",
        "    df[\"Author\"].astype(str) + \" | \" +\n",
        "    df[\"Description\"].astype(str)\n",
        ")\n",
        "\n",
        "# 3ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Embeddings\n",
        "print(\"ğŸ” Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨Ø­Ø«...\")\n",
        "\n",
        "# ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© GPU\n",
        "if 'embeddings' in locals() or 'embeddings' in globals():\n",
        "    del embeddings\n",
        "if 'model' in locals() or 'model' in globals():\n",
        "    del model\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø°Ø§ÙƒØ±Ø© GPU.\")\n",
        "\n",
        "# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµØ­ÙŠØ­ all-MiniLM-L6-v2\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø¯ÙØ¹Ø© ØµØºÙŠØ±\n",
        "BATCH_SIZE = 16\n",
        "embeddings = model.encode(df[\"text\"].tolist(), show_progress_bar=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "embeddings_array = np.array(embeddings).astype('float32')\n",
        "index = faiss.IndexFlatL2(embeddings_array.shape[1])\n",
        "index.add(embeddings_array)\n",
        "print(f\"âœ… Ø¬Ø§Ù‡Ø²! ({len(df)} ÙƒØªØ§Ø¨)\")\n",
        "\n",
        "# 4ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« + Gemini (Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø®Ø±Ø¬Ø§Øª)\n",
        "def ask_gemini(query, k=3):\n",
        "    \"\"\"Ø¨Ø­Ø« Ø°ÙƒÙŠ Ù…Ø¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ù† Gemini\"\"\"\n",
        "\n",
        "    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)\n",
        "    query_emb = model.encode([query]).astype('float32')\n",
        "    distances, indices = index.search(query_emb, k)\n",
        "\n",
        "    books_info = []\n",
        "    for idx in indices[0]:\n",
        "        book = df.iloc[idx]\n",
        "        books_info.append(f\"\"\"\n",
        "ğŸ“– {book['Title']}\n",
        "âœï¸ Ø§Ù„Ù…Ø¤Ù„Ù: {book['Author']}\n",
        "ğŸ“ Ø§Ù„ÙˆØµÙ: {book['Description'][:300]}\n",
        "\"\"\")\n",
        "    context = \"\\n\\n\".join(books_info)\n",
        "\n",
        "    # Ø¥Ø¹Ø¯Ø§Ø¯ Prompt Ù„Ù€ Gemini (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)\n",
        "    prompt = f\"\"\"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØªØ¨Ø© Ø°ÙƒÙŠ. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n",
        "{context}\n",
        "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {query}\n",
        "Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙÙŠØ¯Ø© ÙˆÙ…Ø®ØªØµØ±Ø© (3-4 Ø¬Ù…Ù„ ÙÙ‚Ø·)ØŒ ÙˆØ§Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Gemini\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "\n",
        "        # ğŸš¨ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© Ù„Ø·Ø¨Ø§Ø¹Ø© Ù†Ø¸ÙŠÙØ©:\n",
        "        print(\"\\n**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**\")\n",
        "        print(response.text)\n",
        "\n",
        "        # ğŸ“š Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©\n",
        "        print(\"\\n--- Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© ---\")\n",
        "\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            book = df.iloc[idx]\n",
        "            print(f\"{i+1}. {book['Title']} - {book['Author']}\")\n",
        "        # --------------------------------------------------\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ Gemini: {e}\")\n",
        "        print(\"ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© (ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯):\")\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            book = df.iloc[idx]\n",
        "            print(f\"\\n{i+1}. ğŸ“– {book['Title']}\")\n",
        "            print(f\" Â  âœï¸ {book['Author']}\")\n",
        "            print(f\" Â  ğŸ“ {book['Description'][:200]}...\")\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ§ª ØªØ¬Ø±Ø¨Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©)\n",
        "# ==========================================\n",
        "print(\"\\n\\nâœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø²!\")\n",
        "\n",
        "# ÙˆØ¶Ø¹ ØªÙØ§Ø¹Ù„ÙŠ\n",
        "print(\"\\n\\nğŸ’¬ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø³Ø¤Ø§Ù„ (Ø£Ùˆ 'Ø®Ø±ÙˆØ¬' Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡):\")\n",
        "while True:\n",
        "    # ğŸš¨ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù€ '\\n' Ù…Ù† Ø³Ø·Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø³Ø·Ø± ÙØ§Ø±Øº\n",
        "    q = input(\"â“ Ø³Ø¤Ø§Ù„Ùƒ: \").strip()\n",
        "    if q.lower() in ['Ø®Ø±ÙˆØ¬', 'exit']:\n",
        "        break\n",
        "    if q:\n",
        "        ask_gemini(q)"
      ],
      "metadata": {
        "id": "rnIEKkTUPywa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}